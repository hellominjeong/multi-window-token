
import torch
from typing import Tuple, Callable

def do_nothing(x: torch.Tensor, mode: str = None):
    return x

def mps_gather_workaround(input, dim, index):
    if input.shape[-1] == 1:
        return torch.gather(
            input.unsqueeze(-1),
            dim - 1 if dim < 0 else dim,
            index.unsqueeze(-1)
        ).squeeze(-1)
    else:
        return torch.gather(input, dim, index)

def create_windows(metric: torch.Tensor, w: int, h: int, window_size: int) -> Tuple[torch.Tensor, int, int]:
    """
    Converts token data to windows.

    Args:
        metric (torch.Tensor): Input tensor [B, N, C].
        w (int): Width of the image in tokens.
        h (int): Height of the image in tokens.
        window_size (int): Size of the window.

    Returns:
        Tuple[torch.Tensor, int, int]: Windows tensor, num_windows_h, num_windows_w.
    """
    # print("create_windows----")
    B, N, C = metric.shape
    assert N == w * h, "The metric size doesn't match width and height."

    # Reshape to [B, H, W, C]
    metric_reshaped = metric.view(B, h, w, C)

    # Create windows: [B, num_windows_h, num_windows_w, window_size, window_size, C]
    num_windows_h = h // window_size
    num_windows_w = w // window_size
    windows = metric_reshaped.unfold(1, window_size, window_size).unfold(2, window_size, window_size)

    # Flatten windows: [B, num_windows, window_size * window_size, C]
    windows = windows.contiguous().view(
        B, num_windows_h * num_windows_w, window_size * window_size, C
    )
    
    return windows, num_windows_h, num_windows_w

def calculate_similarity(windows: torch.Tensor) -> torch.Tensor:
    """
    Calculate cosine similarity between windows without averaging.

    Args:
        windows (torch.Tensor): Windows tensor [B, num_windows, W*W, C].

    Returns:
        torch.Tensor: Similarity matrix [B, num_windows, num_windows].
    """
    # [B, num_windows, W*W, C] -> [B, num_windows, W*W*C]
    window_features = windows.flatten(start_dim=2)  # ìœˆë„ìš° ë‚´ë¶€ ëª¨ë“  í† í°ì„ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ë³€í™˜

    # ì •ê·œí™”ëœ íŠ¹ì§•ì„ í•œ ë²ˆì— ê³„ì‚°
    norm = torch.norm(window_features, dim=-1, keepdim=True)
    normalized_features = window_features / (norm + 1e-6)

    # ë°°ì¹˜ í–‰ë ¬ ê³± ì‚¬ìš©í•˜ì—¬ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    return torch.bmm(normalized_features, normalized_features.transpose(-2, -1))

# def calculate_similarity(windows: torch.Tensor) -> torch.Tensor:
#     """
#     Calculate cosine similarity between windows.

#     Args:
#         windows (torch.Tensor): Windows tensor [B, num_windows, W*W, C].

#     Returns:
#         torch.Tensor: Similarity matrix [B, num_windows, num_windows].
#     """
#     window_features = windows.mean(dim=2)  # [B, num_windows, C]
#     # ì •ê·œí™”ëœ íŠ¹ì§•ì„ í•œ ë²ˆì— ê³„ì‚°
#     norm = torch.norm(window_features, dim=-1, keepdim=True)
#     normalized_features = window_features / (norm + 1e-6)
#     # ë°°ì¹˜ í–‰ë ¬ ê³±ì…ˆ ì‚¬ìš©
#     return torch.bmm(normalized_features, normalized_features.transpose(-2, -1))
# def merge_windows(windows: torch.Tensor, similarity_matrix: torch.Tensor, r: int, mode="mean") -> torch.Tensor:
#     B, num_windows, window_size, C = windows.shape

#     # âœ… r ê°’ì„ similarity_matrix í¬ê¸° ë‚´ë¡œ ì œí•œ
#     valid_r = min(r, similarity_matrix.shape[-1])

#     # âœ… ìƒìœ„ rê°œì˜ ìœ ì‚¬í•œ ìŒ ì„ íƒ
#     values, indices = similarity_matrix.view(B, -1).topk(valid_r, dim=-1)
#     idx1 = indices // num_windows
#     idx2 = indices % num_windows

#     print(f"Windows before merging mean: {windows.mean()}")

#     # âœ… scatter_() ëŒ€ì‹  ì§ì ‘ ê°’ ë³€ê²½ (gather ì‚¬ìš©)
#     merged_windows = windows.clone()
#     if mode == "mean":
#         merged = (windows.gather(1, idx1.unsqueeze(-1).expand(-1, -1, window_size, C)) + 
#                   windows.gather(1, idx2.unsqueeze(-1).expand(-1, -1, window_size, C))) / 2
#         merged_windows = merged  # ì§ì ‘ í• ë‹¹í•˜ì—¬ ë³€ê²½ ë°˜ì˜

#     print(f"Windows after merging mean: {merged_windows.mean()}")

#     return merged_windows
#     # B, num_windows, window_size, C = windows.shape
#     # valid_r = min(r, similarity_matrix.shape[-1])

#     # # ìƒìœ„ rê°œì˜ ìœ ì‚¬í•œ ìŒ ì„ íƒ
#     # values, indices = similarity_matrix.view(B, -1).topk(valid_r, dim=-1)
#     # idx1 = indices // num_windows
#     # idx2 = indices % num_windows

#     # # ë²¡í„°í™”ëœ ë³‘í•© ì—°ì‚°
#     # merged_windows = windows.clone()
#     # if mode == "mean":
#     #     # ì¸ë±ì‹±ì„ ì‚¬ìš©í•œ ë²¡í„°í™”ëœ ì—°ì‚°
#     #     merged = (windows[torch.arange(B).unsqueeze(1), idx1] + 
#     #               windows[torch.arange(B).unsqueeze(1), idx2]) / 2
#     #     merged_windows.scatter_(1, idx1.unsqueeze(-1).unsqueeze(-1).expand(-1, -1, window_size, C), merged)

#     # return merged_windows
#     # # ìƒìœ„ rê°œì˜ ìœ ì‚¬í•œ ìŒ ì„ íƒ
#     # values, indices = similarity_matrix.view(B, -1).topk(r, dim=-1)
#     # idx1 = indices // num_windows
#     # idx2 = indices % num_windows
    
#     # # ë²¡í„°í™”ëœ ë³‘í•© ì—°ì‚°
#     # merged_windows = windows.clone()
#     # if mode == "mean":
#     #     # ì¸ë±ì‹±ì„ ì‚¬ìš©í•œ ë²¡í„°í™”ëœ ì—°ì‚°
#     #     merged = (windows[torch.arange(B).unsqueeze(1), idx1] + 
#     #              windows[torch.arange(B).unsqueeze(1), idx2]) / 2
#     #     merged_windows.scatter_(1, idx1.unsqueeze(-1).unsqueeze(-1).expand(-1, -1, window_size, C), merged)
    
#     # return merged_windows

import torch
import torch.nn.functional as F
import torch
import torch.nn.functional as F

# def merge_windows(windows: torch.Tensor, similarity_matrix: torch.Tensor, r: int, mode="mean") -> torch.Tensor:
#     """
#     Merge similar windows using similarity matrix.

#     Args:
#         windows (torch.Tensor): Windows tensor [B, num_windows, window_size, C].
#         similarity_matrix (torch.Tensor): Similarity matrix [B, num_windows, num_windows].
#         r (int): Number of merges to perform.
#         mode (str): Merge mode ('mean' or 'sum').

#     Returns:
#         torch.Tensor: Merged windows tensor.
#     """
#     B, num_windows, window_size, C = windows.shape

#     # âœ… Merge ë¨¼ì € ìˆ˜í–‰
#     valid_r = min(r, similarity_matrix.shape[-1])
#     values, indices = similarity_matrix.view(B, -1).topk(valid_r, dim=-1)
#     idx1 = indices // num_windows
#     idx2 = indices % num_windows

#     merged_windows = windows.clone()

#     if mode == "mean":
#         # idx1_expanded = idx1.unsqueeze(-1).repeat(1, 1, window_size).unsqueeze(-1)
#         # idx2_expanded = idx2.unsqueeze(-1).repeat(1, 1, window_size).unsqueeze(-1)
#         idx1_expanded = idx1.unsqueeze(-1).unsqueeze(-1).expand(-1, -1, window_size, C)
#         idx2_expanded = idx2.unsqueeze(-1).unsqueeze(-1).expand(-1, -1, window_size, C)
#         merged = (windows.gather(1, idx1_expanded) + windows.gather(1, idx2_expanded)) / 2
#         merged_windows = merged  # ì§ì ‘ í• ë‹¹í•˜ì—¬ ë³€ê²½ ë°˜ì˜

#     print(f"Windows after merging shape: {merged_windows.shape}, mean: {merged_windows.mean()}")

#     return merged_windows
import torch

def merge_windows(windows: torch.Tensor, similarity_matrix: torch.Tensor, r: int, mode="mean") -> torch.Tensor:
    """
    Merge similar windows using similarity matrix and remove r windows.

    Args:
        windows (torch.Tensor): Windows tensor [B, num_windows, window_size, C].
        similarity_matrix (torch.Tensor): Similarity matrix [B, num_windows, num_windows].
        r (int): Number of merges to perform.
        mode (str): Merge mode ('mean' or 'sum').

    Returns:
        torch.Tensor: Reduced merged windows tensor [B, num_windows - r, window_size, C].
    """
    # print("merge_windows----")
    B, num_windows, window_size, C = windows.shape
    # similarity_matrix = similarity_matrix.clone()
    # similarity_matrix[:, torch.arange(num_windows), torch.arange(num_windows)] = float('-inf')
    # # âœ… Merge ìˆ˜í–‰ (rê°œì˜ ìœˆë„ìš°ë¥¼ ì„ íƒ)
    # valid_r = min(r, num_windows // 2, similarity_matrix.shape[-1]) 
    # values, indices = similarity_matrix.view(B, -1).topk(valid_r, dim=-1)  

    # idx1 = indices // num_windows  # ì²« ë²ˆì§¸ ìœˆë„ìš° ì¸ë±ìŠ¤
    # idx2 = indices % num_windows  # ë‘ ë²ˆì§¸ ìœˆë„ìš° ì¸ë±ìŠ¤
    
    similarity_matrix = similarity_matrix.clone()
    similarity_matrix[:, torch.arange(num_windows), torch.arange(num_windows)] = float('-inf')  # ìê¸° ìì‹  ì œì™¸
    r_windows = int(num_windows * 0.5)  # ì…ë ¥ í…ì„œ ê¸°ë°˜ì´ ì•„ë‹ˆë¼, ìœˆë„ìš° ê°œìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜
    valid_r = min(r_windows, num_windows // 2)  # ë™ì¼í•œ ê¸°ì¤€ìœ¼ë¡œ ë¹„êµ
    # valid_r = min(r, num_windows // 2, similarity_matrix.shape[-1]) 
    # print("valid_r: ",valid_r)
    # print("r: ",r_windows)
    # âœ… ì„ íƒëœ ìœˆë„ìš°ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
    selected_idx1 = []
    selected_idx2 = []
    num_selected = 0
    # print(f"num_selected: {num_selected}, valid_r: {valid_r}")
    while num_selected < valid_r:
        # print("in while ---- sim matrix before view", similarity_matrix.shape)
        values, indices = similarity_matrix.view(B, -1).topk(valid_r - num_selected, dim=-1)  # ì•„ì§ í•„ìš”í•œ ê°œìˆ˜ë§Œí¼ë§Œ ê°€ì ¸ì˜¤ê¸°
        new_idx1 = indices // num_windows
        new_idx2 = indices % num_windows
        # print("new idx1: ",new_idx1.shape)
        # print("new idx2: ",new_idx2.shape)

        valid_pairs = new_idx1 != new_idx2 
        # print("valid_pairs",valid_pairs.shape)
        valid_pairs = valid_pairs.view(B, -1)
        # print("valid_pairs.view",valid_pairs.shape)
        # new_idx1 = new_idx1[valid_pairs]
        
        # new_idx2 = new_idx2[valid_pairs]
        new_idx1 = torch.where(valid_pairs, new_idx1, -1)  # -1ì„ ì±„ì›Œì„œ êµ¬ì¡° ìœ ì§€
        new_idx2 = torch.where(valid_pairs, new_idx2, -1)

        valid_range = (new_idx1 < num_windows) & (new_idx2 < num_windows)
        # print("valid_range",valid_range.shape)
        valid_range = valid_range.view(B, -1)  # ë°°ì¹˜ ì°¨ì› ìœ 
        # print("valid_range.view",valid_range.shape)
        # new_idx1 = new_idx1[valid_range]
        # new_idx2 = new_idx2[valid_range]
        new_idx1 = torch.where(valid_range, new_idx1, -1)
          # -1ì„ ì±„ì›Œì„œ êµ¬ì¡° ìœ ì§€
        new_idx2 = torch.where(valid_range, new_idx2, -1)
        # print("Filtered new_idx1: ", new_idx1.shape)
        # print("Filtered new_idx2: ", new_idx2.shape)

        # # âœ… 3. `num_selected` ì—…ë°ì´íŠ¸
        # print("new_idx1.shape", new_idx1.shape)
        num_selected += new_idx1.shape[1]  # ì‹¤ì œ ë³‘í•©ëœ ê°œìˆ˜ë§Œí¼ ì—…ë°ì´íŠ¸
        # print(f"Updated num_selected: {num_selected}/{valid_r}")

        # âœ… ë§Œì•½ num_selectedê°€ ë” ì´ìƒ ì¦ê°€í•˜ì§€ ì•Šìœ¼ë©´ (ì˜ˆ: ëª¨ë“  ë³‘í•© ê°€ëŠ¥í•œ ìœˆë„ìš°ë¥¼ ë‹¤ ì°¾ì•˜ì„ ë•Œ) ì¢…ë£Œ
        if new_idx1.shape[0] == 0:
            print("âš  No more valid pairs to merge. Exiting loop.")
            break
        # âœ… ì¤‘ë³µ ì œê±°
        # mask = ~torch.isin(new_idx1, torch.tensor(selected_idx1, device=similarity_matrix.device)) & \
        #     ~torch.isin(new_idx2, torch.tensor(selected_idx2, device=similarity_matrix.device))
        # mask1 = ~torch.isin(new_idx1, torch.tensor(selected_idx1, device=similarity_matrix.device).unsqueeze(0))
        # mask2 = ~torch.isin(new_idx2, torch.tensor(selected_idx2, device=similarity_matrix.device).unsqueeze(0))

    #     # âœ… batch-wise AND ì—°ì‚° ì ìš©
    #     mask = mask1 & mask2  # ì´ì œ (2, 128) ì°¨ì› ìœ ì§€ë¨
    #     new_idx1 = new_idx1[mask].view(B, -1)
    #     new_idx2 = new_idx2[mask].view(B, -1)
    #     print("after ì¤‘ë³µì œê±° --------------------")
    #     print("new idx1: ",new_idx1.shape)
    #     print("new idx2: ",new_idx2.shape)
    #     # âœ… ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•˜ë©´ì„œ ì •í™•íˆ 128ê°œë¥¼ ìœ ì§€
    #     selected_idx1.extend(new_idx1.tolist())
    #     selected_idx2.extend(new_idx2.tolist())
    #     num_selected = len(selected_idx1[1])  # ì—…ë°ì´íŠ¸
    #     print("num_selected: ",num_selected)

    # # âœ… ìµœì¢… ì„ íƒëœ ì¸ë±ìŠ¤ë¥¼ í…ì„œë¡œ ë³€í™˜
    # idx1 = torch.tensor(selected_idx1, device=similarity_matrix.device).view(B, -1)
    # idx2 = torch.tensor(selected_idx2, device=similarity_matrix.device).view(B, -1)

    # print(f"idx1 unique count: {len(torch.unique(idx1))}")
    # print(f"idx2 unique count: {len(torch.unique(idx2))}")
    # print(f"idx1.shape before filtering: {idx1.shape}")
    # print(f"idx2.shape before filtering: {idx2.shape}") 
    # # merged = (windows[:, idx1] + windows[:, idx2]) / 2  # ë‘ ìœˆë„ìš° í‰ê·  ë‚´ê¸°
    # unique_pairs = idx1 != idx2  # ê°™ì€ ìœˆë„ìš°ê°€ ì„ íƒë˜ì§€ ì•Šë„ë¡ í•„í„°ë§
    # idx1_filtered = [torch.masked_select(idx1[b], unique_pairs[b]) for b in range(B)]
    # idx2_filtered = [torch.masked_select(idx2[b], unique_pairs[b]) for b in range(B)]
    # idx1_final = torch.cat(idx1_filtered).view(B, -1)
    # idx2_final = torch.cat(idx2_filtered).view(B, -1)

    # print(f"idx1.shape after filtering: {idx1_final.shape}")
    # print(f"idx2.shape after filtering: {idx2_final.shape}")
    # unique_idx2, inverse_indices, counts = torch.unique(idx2_final, return_inverse=True, return_counts=True)
    # duplicate_idx2 = unique_idx2[counts > 1]  # ì¤‘ë³µëœ idx2 ì°¾ê¸°
    # if unique_idx2.shape[0] > valid_r:
    #     unique_idx2 = unique_idx2[:valid_r]  # valid_r ê°œë§Œ ìœ ì§€
    # print(f"Unique idx2 count after fixing: {unique_idx2.shape[0]} (Expected: {valid_r})")

    # # âœ… ë³‘í•© ìˆ˜í–‰
    merged = (windows[:, new_idx1] + windows[:, new_idx2]) / 2  
    merged = merged.mean(dim=1)  # âœ… ì°¨ì› ì¡°ì •
    # print(f"merged.shape: {merged.shape}")
    # print(f"merged mean: {merged.mean()}, merged shape after mean: {merged.shape}")
    actual_r = new_idx1.shape[1]  # ì‹¤ì œ ë³‘í•©ëœ ê°œìˆ˜ ë°˜ì˜
    # print(f"actual_r after filtering: {actual_r}")
    if actual_r == 0:
        print("âš  Warning: No valid merge pairs found. Skipping merge step.")
        return windows
    # merged = (windows[:, idx1_final] + windows[:, idx2_final]) / 2
    # merged = merged.mean(dim=1)
    # # merged = (windows.gather(1, idx1_final.unsqueeze(-1).expand(-1, -1, window_size, C)) + 
    # #           windows.gather(1, idx2_final.unsqueeze(-1).expand(-1, -1, window_size, C))) / 2

    # actual_r = idx1_final.shape[1]  # ì‹¤ì œ ë³‘í•©ëœ ê°œìˆ˜ ë°˜ì˜
    # print(f"actual_r after filtering: {actual_r}")

    # if actual_r == 0:
    #     print("âš  Warning: No valid merge pairs found. Skipping merge step.")
    #     return windows

    # âœ… ê¸°ì¡´ ìœˆë„ìš°ì—ì„œ ì œê±°í•  ìœˆë„ìš° ì œì™¸
    # mask = torch.ones(num_windows, device=windows.device, dtype=torch.bool)
    # idx2_final_unique = torch.unique(idx2_final)  # ì¤‘ë³µ ì œê±°
    # print("idx2_final_unique : ", idx2_final_unique)
    # mask[idx2_final_unique.flatten()] = False  # ì œê±°í•  ìœˆë„ìš° Falseë¡œ ì„¤ì •
    # print(f"mask.sum(): {mask.sum()}")
    # print("unique_idx2 : ", unique_idx2)
    # # ğŸ”¥ ì¶”ê°€ ìˆ˜ì •: unique_idx2ì™€ duplicate_idx2ë„ Falseë¡œ ì„¤ì •
    # mask[unique_idx2] = False  
    # print(f"mask.sum(): {mask.sum()}")
    # print("duplicate_idx2 : ", duplicate_idx2)
    # mask[duplicate_idx2] = False  

    '''
    mask[idx2_final.flatten()] = False  
    # unique_idx2, counts = torch.unique(idx2_final, return_counts=True)
    mask[unique_idx2] = False  # ì¤‘ë³µ ì œê±°ëœ idx2ë§Œ False ì²˜ë¦¬
    mask[duplicate_idx2] = False  # ğŸ›‘ ì¶”ê°€: ì¤‘ë³µëœ idx2ë„ Falseë¡œ ì²˜ë¦¬  
    '''
    
    # print(f"mask.sum(): {mask.sum()} (Should be {num_windows - actual_r})")
    # remaining_windows = windows[:, mask]
    # print(f"remaining_windows.shape: {remaining_windows.shape}")

    # print(f"merged.shape before fixing: {merged.shape}")  
    # âœ… ë³‘í•©ëœ ìœˆë„ìš°ì™€ ë‚¨ì€ ìœˆë„ìš° í•©ì¹˜ê¸°
    #merged_windows = torch.cat([remaining_windows, merged], dim=1)

    merged_windows = merged
    # print(f"Windows after merging shape: {merged_windows.shape}, mean: {merged_windows.mean()}")

    return merged_windows, actual_r
# # ğŸ› ï¸ ë””ë²„ê¹… ì¶œë ¥
#     print(f"Unique idx2 count: {unique_idx2.shape[0]} (Expected: {idx2.numel()})")
#     print(f"Duplicate indices count: {(counts > 1).sum().item()}")  # ëª‡ ê°œì˜ ì¸ë±ìŠ¤ê°€ ì¤‘ë³µë˜ì—ˆëŠ”ì§€ ì¶œë ¥
#     # mask[idx2_final.flatten()] = False  # idx2ì— í•´ë‹¹í•˜ëŠ” ìœˆë„ìš°ë¥¼ ì œê±°
#     mask[unique_idx2] = False 
#     print(f"mask.sum(): {mask.sum()} (Should be less than {num_windows})")
#     remaining_windows = windows[:, mask]
#     print(f"remaining_windows.shape: {remaining_windows.shape}")

#     print(f"merged.shape before fixing: {merged.shape}")  
#     # âœ… ë³‘í•©ëœ ìœˆë„ìš°ì™€ ë‚¨ì€ ìœˆë„ìš° í•©ì¹˜ê¸°
#     merged_windows = torch.cat([remaining_windows, merged], dim=1)

#     print(f"Windows after merging shape: {merged_windows.shape}, mean: {merged_windows.mean()}")

#     return merged_windows
    # # ë‹¤ì‹œ ë¦¬ìŠ¤íŠ¸ë¥¼ í…ì„œë¡œ ë³€í™˜ (ê¸¸ì´ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ íŒ¨ë”© í•„ìš”)
    # max_len = max(x.shape[0] for x in idx1_filtered) if idx1_filtered else 0
    # idx1_padded = torch.stack([torch.cat([x, torch.full((max_len - x.shape[0],), -1, dtype=torch.long, device=x.device)]) for x in idx1_filtered])
    # idx2_padded = torch.stack([torch.cat([x, torch.full((max_len - x.shape[0],), -1, dtype=torch.long, device=x.device)]) for x in idx2_filtered])

    # print(f"idx1.shape after filtering: {idx1_padded.shape}")  # Expected: [B, new_valid_r]
    # print(f"idx2.shape after filtering: {idx2_padded.shape}")
    # merged = (windows[:, idx1_padded] + windows[:, idx2_padded]) / 2  # ì˜¬ë°”ë¥¸ ë³‘í•© ìˆ˜í–‰
    # # âœ… unique_pairsë¡œ í•„í„°ë§í•œ í›„ ì‹¤ì œ rê°’ì„ ë‹¤ì‹œ ê³„ì‚°
    # actual_r = idx1_padded.shape[1] if idx1_padded.dim() == 2 else idx1_padded.shape[0]
    # print(f"actual_r after filtering: {actual_r}")


    # # âœ… unique_pairsë¡œ í•„í„°ë§í•œ í›„ ì‹¤ì œ rê°’ì„ ë‹¤ì‹œ ê³„ì‚°
    # # actual_r = idx1.shape[1]  # í•„í„°ë§ëœ ë³‘í•© ê°œìˆ˜
    # if idx1.dim() == 1:  # idx1ì´ 1ì°¨ì›ì¼ ê²½ìš°
    #     actual_r = idx1.shape[0]  # ì²« ë²ˆì§¸ ì°¨ì›ì„ ì‚¬ìš©
    # else:
    #     actual_r = idx1.shape[1]  # ê¸°ì¡´ ë°©ì‹ ìœ ì§€
    # print(f"actual_r after filtering: {actual_r}")

    # if actual_r == 0:
    #     print("âš  Warning: No valid merge pairs found. Skipping merge step.")
    #     return windows  # ë³‘í•© ì—†ì´ ì›ë³¸ ë°˜í™˜

    # merged = merged[:, :actual_r]  # ì‹¤ì œ ë³‘í•© ê°œìˆ˜ì— ë§ê²Œ ìë¥´ê¸°

    # mask = torch.ones(num_windows, device=windows.device, dtype=torch.bool)
    # mask[idx2.flatten()] = False  # idx2ì— í•´ë‹¹í•˜ëŠ” ìœˆë„ìš°ë¥¼ ì œê±°

    
    # remaining_windows = windows[:, mask]  # ì œê±°ëœ ìœˆë„ìš° ì œì™¸
    # print("valid_r :  ", actual_r)
    # print("merged.shape before view:", merged.shape)
    # merged = merged.view(B, actual_r, window_size, C)  # valid_r ëŒ€ì‹  actual_r ì‚¬ìš©
    # # merged = merged[:, unique_pairs] ////////////////
    # # merged = merged.mean(dim=1)  # âœ… ë‘ ë²ˆì§¸ ì°¨ì› ì œê±°
    # # # âœ… ì„ íƒëœ ìœˆë„ìš° ë³‘í•©
    # # if mode == "mean":
    # #     merged = (windows[:, idx1] + windows[:, idx2]) / 2  # ë‘ ìœˆë„ìš° í‰ê·  ë‚´ê¸°
    # # elif mode == "sum":
    # #     merged = windows[:, idx1] + windows[:, idx2]  # ë‘ ìœˆë„ìš° ë”í•˜ê¸°
    # # else:
    # #     raise ValueError("Invalid mode. Choose 'mean' or 'sum'.")

    # # âœ… ê¸°ì¡´ ìœˆë„ìš°ì—ì„œ ì œê±°í•  ìœˆë„ìš° ì œì™¸
    # # mask = torch.ones(num_windows, device=windows.device, dtype=torch.bool)
    # # mask[idx2.flatten()] = False  # idx2ì— í•´ë‹¹í•˜ëŠ” ìœˆë„ìš°ë¥¼ ì œê±°

    # # âœ… ë‚¨ì€ ìœˆë„ìš°ë“¤ë§Œ ì„ íƒ
    # # remaining_windows = windows[:, mask]  # ì œê±°ëœ ìœˆë„ìš° ì œì™¸
    # # print("valid_r :  ", valid_r)
    # # print("merged.shape before view:", merged.shape)
    # # merged = merged.view(B, valid_r, window_size, C)  # valid_r ì°¨ì› ì œê±°
    
    # # âœ… ë³‘í•©ëœ ìœˆë„ìš°ì™€ ë‚¨ì€ ìœˆë„ìš° í•©ì¹˜ê¸°
    # merged_windows = torch.cat([remaining_windows, merged], dim=1)  # ë³‘í•©ëœ ìœˆë„ìš° ì¶”ê°€

    # print(f"Windows after merging shape: {merged_windows.shape}, mean: {merged_windows.mean()}")

    # return merged_windows  # ìµœì¢… ìœˆë„ìš° ê°œìˆ˜: num_windows - r

# def reconstruct_from_windows(windows: torch.Tensor, num_windows_h: int, num_windows_w: int, window_size: int, h: int, w: int) -> torch.Tensor:
#     """
#     Reconstruct the image from windows.

#     Args:
#         windows (torch.Tensor): Windows tensor [B, num_windows, W*W, C].
#         num_windows_h (int): Number of windows along height.
#         num_windows_w (int): Number of windows along width.
#         window_size (int): Size of the window.
#         h (int): Original height of the image.
#         w (int): Original width of the image.

#     Returns:
#         torch.Tensor: Reconstructed image tensor [B, N, C].
#     """
#     B, num_windows, _, C = windows.shape

#     # Reshape windows: [B, num_windows_h, num_windows_w, window_size, window_size, C]
#     windows = windows.view(B, num_windows_h, num_windows_w, window_size, window_size, C)

#     # Combine windows back into the image
#     reconstructed = windows.permute(0, 1, 3, 2, 4, 5).contiguous()
#     reconstructed = reconstructed.view(B, h, w, C)
#     return reconstructed.view(B, h * w, C)
import torch
import math

# def reconstruct_from_windows(windows: torch.Tensor, num_windows_h: int, num_windows_w: int, window_size: int, h: int, w: int) -> torch.Tensor:
#     """
#     Mergeëœ ìœˆë„ìš°ë¥¼ ë‹¤ì‹œ ì›ë³¸ í¬ê¸° (h, w)ë¡œ ë³µì›.

#     Args:
#         windows (torch.Tensor): Windows tensor [B, num_windows, W*W, C].
#         num_windows_h (int): ë³‘í•© í›„ ë‚¨ì€ ìœˆë„ìš°ì˜ ë†’ì´ ê°œìˆ˜.
#         num_windows_w (int): ë³‘í•© í›„ ë‚¨ì€ ìœˆë„ìš°ì˜ ë„ˆë¹„ ê°œìˆ˜.
#         window_size (int): ê° ìœˆë„ìš° í¬ê¸°.
#         h (int): ì›ë³¸ ì´ë¯¸ì§€ ë†’ì´.
#         w (int): ì›ë³¸ ì´ë¯¸ì§€ ë„ˆë¹„.

#     Returns:
#         torch.Tensor: Reconstructed image tensor [B, h*w, C].
#     """
#     B, num_windows, _, C = windows.shape

#     # âš  ë™ì ìœ¼ë¡œ num_windows_h, num_windows_w ì¡°ì •
#     num_windows_h = math.isqrt(num_windows)  # ì •ì‚¬ê°í˜•ì— ê°€ê¹Œìš´ ê°’
#     num_windows_w = num_windows // num_windows_h  # ë„ˆë¹„ ê³„ì‚°

#     if num_windows_h * num_windows_w != num_windows:
#         print(f"âš  Warning: Adjusting num_windows_h and num_windows_w. Expected: {num_windows}, Actual: {num_windows_h * num_windows_w}")
#         return windows  # ì›ë³¸ ë°˜í™˜

#     # âœ… ìœˆë„ìš°ë¥¼ ì›ë˜ ê³µê°„ìœ¼ë¡œ ë³µì›
#     windows = windows.view(B, num_windows_h, num_windows_w, window_size, window_size, C)
#     reconstructed = windows.permute(0, 1, 3, 2, 4, 5).contiguous()
#     reconstructed = reconstructed.view(B, num_windows_h * window_size, num_windows_w * window_size, C)
#     # return reconstructed
#     return reconstructed.view(B, num_windows_h * window_size * num_windows_w * window_size, C)
#----
# def reconstruct_from_windows(windows: torch.Tensor, num_windows_h: int, num_windows_w: int, 
#                              window_size: int, num_windows: int) -> torch.Tensor:
#     """
#     ìœˆë„ìš° í˜•íƒœë¥¼ ì›ë˜ ì´ë¯¸ì§€ ê³µê°„ìœ¼ë¡œ ë³µì›í•˜ëŠ” í•¨ìˆ˜.

#     Args:
#         windows (torch.Tensor): ìœˆë„ìš° í…ì„œ [B, num_windows, W*W, C]
#         num_windows_h (int): ë†’ì´ ë°©í–¥ ìœˆë„ìš° ê°œìˆ˜
#         num_windows_w (int): ë„ˆë¹„ ë°©í–¥ ìœˆë„ìš° ê°œìˆ˜
#         window_size (int): ê°œë³„ ìœˆë„ìš° í¬ê¸°
#         num_windows (int): ì‹¤ì œ ìœˆë„ìš° ê°œìˆ˜

#     Returns:
#         torch.Tensor: ë³µì›ëœ ì´ë¯¸ì§€ [B, N, C] í˜•íƒœ
#     """
#     B, actual_num_windows, _, C = windows.shape

#     # âœ… `num_windows_h * num_windows_w`ê°€ `num_windows`ì™€ ë‹¤ë¥¼ ê²½ìš° ì¡°ì •
#     if num_windows_h * num_windows_w != num_windows:
#         print(f"âš  Warning: Adjusting num_windows_h and num_windows_w. Expected: {num_windows}, Actual: {num_windows_h * num_windows_w}")
        
#         # ê°€ì¥ ê°€ê¹Œìš´ num_windows_hì™€ num_windows_w ì°¾ê¸°
#         factor_pairs = [(h, num_windows // h) for h in range(1, num_windows + 1) if num_windows % h == 0]
#         best_pair = min(factor_pairs, key=lambda p: abs(p[0] - p[1]))  # ê°€ì¥ ë¹„ìœ¨ì´ ë¹„ìŠ·í•œ ì¡°í•© ì„ íƒ
#         num_windows_h, num_windows_w = best_pair

#         print(f"ğŸ”„ Adjusted num_windows_h: {num_windows_h}, num_windows_w: {num_windows_w}")

#     # âœ… `view()`ë¥¼ ì‚¬ìš©í•˜ê¸° ì „ì— í¬ê¸° ë§ì¶”ê¸°
#     try:
#         windows = windows.view(B, num_windows_h, num_windows_w, window_size, window_size, C)
#     except RuntimeError as e:
#         print(f"âŒ view() ì‹¤íŒ¨: {e}, windows.shape: {windows.shape}, num_windows_h: {num_windows_h}, num_windows_w: {num_windows_w}")
#         return windows  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ë³¸ ìœˆë„ìš° ë°˜í™˜

#     # âœ… ìœˆë„ìš°ë¥¼ ë‹¤ì‹œ ì´ë¯¸ì§€ í˜•íƒœë¡œ ë³µì›
#     reconstructed = windows.permute(0, 1, 3, 2, 4, 5).contiguous()
#     reconstructed = reconstructed.view(B, num_windows_h * window_size, num_windows_w * window_size, C)

#     # âœ… `[B, N, C]` í˜•íƒœë¡œ ë³€í™˜
#     return reconstructed.view(B, num_windows_h * window_size * num_windows_w * window_size, C)
#---
import torch
import torch.nn.functional as F

def window_based_soft_matching(
    input_tensor: torch.Tensor,
    w: int,
    h: int,
    r: int,
    mode="mean"
) -> torch.Tensor:
    """
    Perform window-based soft matching and merging.

    Args:
        input_tensor (torch.Tensor): Input tensor [B, N, C].
        w (int): Width of the image in tokens.
        h (int): Height of the image in tokens.
        r (int): Number of merges to perform.
        mode (str): Merge mode ('mean' or 'sum').

    Returns:
        torch.Tensor: Reconstructed tensor [B, N, C].
    """
    B, N, C = input_tensor.shape
    device = input_tensor.device
    # print("input tensor: ===========================")
    # print(input_tensor.shape)
    windows_4, num_windows_h_4, num_windows_w_4 = create_windows(input_tensor, w, h, window_size=4)
    similarity_matrix_4 = calculate_similarity(windows_4)
    merged_windows_4, numw4 = merge_windows(windows_4, similarity_matrix_4, r, mode)
    
    windows_8, num_windows_h_8, num_windows_w_8 = create_windows(input_tensor, w, h, window_size=8)
    similarity_matrix_8 = calculate_similarity(windows_8)
    merged_windows_8, numw8 = merge_windows(windows_8, similarity_matrix_8, r, mode)

    windows_16, num_windows_h_16, num_windows_w_16 = create_windows(input_tensor, w, h, window_size=16)
    similarity_matrix_16 = calculate_similarity(windows_16)
    merged_windows_16, numw16 = merge_windows(windows_16, similarity_matrix_16, r, mode)

    merged_windows_4 = merged_windows_4.permute(0, 3, 1, 2)
    merged_windows_16 = merged_windows_16.permute(0, 3, 1, 2)
    target_size = (merged_windows_8.shape[1], merged_windows_8.shape[2])  # (102, 16)
    print("---------------------")
    print("merged_windows_4: ",merged_windows_4.shape)
    print("merged_windows_8: ",merged_windows_8.shape)
    print("merged_windows_16: ",merged_windows_16.shape)

    print("------------------")
    merged_windows_4_resized = F.interpolate(merged_windows_4, 
                                        size=target_size,  # (num_windows, height)
                                        mode='bilinear', align_corners=False)  # Bilinear Interpolation ì‚¬ìš©
    
    merged_windows_16_resized = F.interpolate(merged_windows_16, 
                                        size=target_size,  # (num_windows, height)
                                        mode='bilinear', align_corners=False)  # Bilinear Interpolation ì‚¬ìš©
    
    merged_windows_4_final = merged_windows_4_resized.permute(0, 2, 3, 1)
    merged_windows_16_final = merged_windows_16_resized.permute(0, 2, 3, 1)
    print("merged_windows_4_final: ",merged_windows_4_final.shape)
    print("merged_windows_8: ",merged_windows_8.shape)
    print("merged_windows_16_final: ",merged_windows_16_final.shape)
    print("----------------")
    result = torch.cat([merged_windows_4_final,merged_windows_8, merged_windows_16_final], dim=-1)
    print(result.shape)
    # if merged_windows_4.shape[1] != merged_windows_16.shape[1]:
    #     merged_windows_16 = merged_windows_16.permute(0, 3, 1, 2)
    #     target_size = (merged_windows_4.shape[1], merged_windows_4.shape[2])  # (102, 16)
    #     merged_windows_16_resized = F.interpolate(merged_windows_16, 
    #                                       size=target_size,  # (num_windows, height)
    #                                       mode='bilinear', align_corners=False)  # Bilinear Interpolation ì‚¬ìš©

    # merged_windows_16_final = merged_windows_16_resized.permute(0, 2, 3, 1)
    # result = torch.cat([merged_windows_4, merged_windows_16_final], dim=-1)
    

    # def unmerge_fn(merged_x: torch.Tensor) -> torch.Tensor:
    #     """
    #     Unmerge function to revert back to the original tensor shape.
    #     """
    #     # Concatenation ì´ì „ì˜ ê°œë³„ ìœˆë„ìš° í¬ê¸°ë¥¼ ì•Œì•„ì•¼ ì›ë˜ ìƒíƒœë¡œ ë³µêµ¬ ê°€ëŠ¥
    #     recovered_windows_4 = merged_x[..., :numw4, :]
    #     recovered_windows_16 = merged_x[..., numw4:, :]

    #     # Interpolationì„ í†µí•´ ì›ë˜ í¬ê¸° ë³µì›
    #     recovered_windows_16 = F.interpolate(
    #         recovered_windows_16.permute(0, 3, 1, 2), 
    #         size=(h, w), mode='bilinear', align_corners=False
    #     ).permute(0, 2, 3, 1)

    #     # ì›ë˜ ìœˆë„ìš° í¬ê¸°ëŒ€ë¡œ ë³µêµ¬
    #     reconstructed = (recovered_windows_4 + recovered_windows_16) / 2  # ë‹¨ìˆœ í‰ê·  ë³µêµ¬ (ì¡°ì • ê°€ëŠ¥)
    #     return reconstructed

    def unmerge_fn(merged_x: torch.Tensor, numw4: int, numw8: int, numw16: int, h: int, w: int) -> torch.Tensor:
        """
        Unmerge function to revert back to the original tensor shape.
        """
        # 1. ë³‘í•©ëœ í…ì„œë¥¼ ë¶„ë¦¬
        # 4x4 ìœˆë„ìš° ë³µêµ¬
        recovered_windows_4 = merged_x[..., :, :320]
        
        # 8x8 ìœˆë„ìš°ëŠ” ì›ë˜ í˜•íƒœë¡œ ìœ ì§€
        recovered_windows_8 = merged_x[..., :, 320:640]
        
        # 16x16 ìœˆë„ìš° ë³µêµ¬
        recovered_windows_16 = merged_x[..., :,  :640]

        print("recovered_windows_4: ",recovered_windows_4.shape)
        print("recovered_windows_8: ",recovered_windows_8.shape)
        print("recovered_windows_16: ",recovered_windows_16.shape)

        # 2. 4x4ì™€ 16x16 ìœˆë„ìš° í¬ê¸°ë¥¼ ì›ë˜ì˜ í¬ê¸°ì¸ 8x8ë¡œ ë³´ê°„
        recovered_windows_4_resized = F.interpolate(
            recovered_windows_4.permute(0, 3, 1, 2),  # [B, C, num_windows_h, num_windows_w]
            size=(16, numw4),  # 8x8 ìœˆë„ìš° í¬ê¸°
            mode='bilinear',
            align_corners=False
        ).permute(0, 2, 3, 1)  # [B, num_windows_h, num_windows_w, C]
        
        recovered_windows_16_resized = F.interpolate(
            recovered_windows_16.permute(0, 3, 1, 2),  # [B, C, num_windows_h, num_windows_w]
            size=(h//16, numw16),  # 8x8 ìœˆë„ìš° í¬ê¸°
            mode='bilinear',
            align_corners=False
        ).permute(0, 2, 3, 1)  # [B, num_windows_h, num_windows_w, C]
        print("recovered_windows_4_resized: ",recovered_windows_4_resized.shape)
        print("recovered_windows_16_resized: ",recovered_windows_16_resized.shape)
        # 3. ëª¨ë“  ìœˆë„ìš°ë¥¼ ê²°í•©
        reconstructed = (
            recovered_windows_4_resized + recovered_windows_8 + recovered_windows_16_resized
        ) / 3  # ë‹¨ìˆœ í‰ê· ìœ¼ë¡œ ë³µì›
        print(type(reconstructed))
        
        return reconstructed
    a = unmerge_fn(result, numw4, numw8, numw16, h, w)
    print("---------------", type(a))
    return result, a 



# def window_based_soft_matching(
#     input_tensor: torch.Tensor,
#     w: int,
#     h: int,
#     r: int,
#     mode="mean"
# ) -> torch.Tensor:
#     """
#     Perform window-based soft matching and merging.

#     Args:
#         input_tensor (torch.Tensor): Input tensor [B, N, C].
#         w (int): Width of the image in tokens.
#         h (int): Height of the image in tokens.
#         window_size (int): Size of the window.
#         r (int): Number of merges to perform.
#         mode (str): Merge mode ('mean' or 'sum').

#     Returns:
#         torch.Tensor: Reconstructed tensor [B, N, C].
#     """
#     B, N, C = input_tensor.shape
#     device = input_tensor.device

#     # Process with 4x4 windows
#     windows_4, num_windows_h_4, num_windows_w_4 = create_windows(input_tensor, w, h, window_size=4)
#     similarity_matrix_4 = calculate_similarity(windows_4)
#     merged_windows_4 = merge_windows(windows_4, similarity_matrix_4, r, mode)
#     reconstructed_4 = reconstruct_from_windows(merged_windows_4, num_windows_h_4, num_windows_w_4, 4, h, w)

#     # Process with 16x16 windows
#     windows_16, num_windows_h_16, num_windows_w_16 = create_windows(input_tensor, w, h, window_size=16)
#     similarity_matrix_16 = calculate_similarity(windows_16)
#     merged_windows_16 = merge_windows(windows_16, similarity_matrix_16, r, mode)
#     reconstructed_16 = reconstruct_from_windows(merged_windows_16, num_windows_h_16, num_windows_w_16, 16, h, w)

#     print("Windows 4 shape:", windows_4.shape)
#     print("Windows 16 shape:", windows_16.shape)

#     print("Similarity matrix 4 mean:", similarity_matrix_4.mean())
#     print("Similarity matrix 16 mean:", similarity_matrix_16.mean())

#     print("Windows 4 before merging mean:", windows_4.mean())
#     print("Merged Windows 4 mean:", merged_windows_4.mean())

#     print("Windows 16 before merging mean:", windows_16.mean())
#     print("Merged Windows 16 mean:", merged_windows_16.mean())

#     print("Merging 4 changed?", not torch.equal(windows_4, merged_windows_4))
#     print("Merging 16 changed?", not torch.equal(windows_16, merged_windows_16))



#     # Concatenate results along the channel dimension
#     result = torch.cat([reconstructed_4, reconstructed_16], dim=-1)
    
#     return result
#------ì›ë³¸
# import torch
# from typing import Tuple, Callable


# def do_nothing(x: torch.Tensor, mode:str=None):
#     return x


# def mps_gather_workaround(input, dim, index):
#     if input.shape[-1] == 1:
#         return torch.gather(
#             input.unsqueeze(-1),
#             dim - 1 if dim < 0 else dim,
#             index.unsqueeze(-1)
#         ).squeeze(-1)
#     else:
#         return torch.gather(input, dim, index)


# def bipartite_soft_matching_random2d(metric: torch.Tensor,
#                                      w: int, h: int, sx: int, sy: int, r: int,
#                                      no_rand: bool = False,
#                                      generator: torch.Generator = None) -> Tuple[Callable, Callable]:
#     """
#     Partitions the tokens into src and dst and merges r tokens from src to dst.
#     Dst tokens are partitioned by choosing one randomy in each (sx, sy) region.

#     Args:
#      - metric [B, N, C]: metric to use for similarity
#      - w: image width in tokens
#      - h: image height in tokens
#      - sx: stride in the x dimension for dst, must divide w
#      - sy: stride in the y dimension for dst, must divide h
#      - r: number of tokens to remove (by merging)
#      - no_rand: if true, disable randomness (use top left corner only)
#      - rand_seed: if no_rand is false, and if not None, sets random seed.
#     """
#     B, N, _ = metric.shape

#     if r <= 0:
#         return do_nothing, do_nothing

#     gather = mps_gather_workaround if metric.device.type == "mps" else torch.gather
    
#     with torch.no_grad():
#         hsy, wsx = h // sy, w // sx

#         # For each sy by sx kernel, randomly assign one token to be dst and the rest src
#         if no_rand:
#             rand_idx = torch.zeros(hsy, wsx, 1, device=metric.device, dtype=torch.int64)
#         else:
#             rand_idx = torch.randint(sy*sx, size=(hsy, wsx, 1), device=generator.device, generator=generator).to(metric.device)
        
#         # The image might not divide sx and sy, so we need to work on a view of the top left if the idx buffer instead
#         idx_buffer_view = torch.zeros(hsy, wsx, sy*sx, device=metric.device, dtype=torch.int64)
#         idx_buffer_view.scatter_(dim=2, index=rand_idx, src=-torch.ones_like(rand_idx, dtype=rand_idx.dtype))
#         idx_buffer_view = idx_buffer_view.view(hsy, wsx, sy, sx).transpose(1, 2).reshape(hsy * sy, wsx * sx)

#         # Image is not divisible by sx or sy so we need to move it into a new buffer
#         if (hsy * sy) < h or (wsx * sx) < w:
#             idx_buffer = torch.zeros(h, w, device=metric.device, dtype=torch.int64)
#             idx_buffer[:(hsy * sy), :(wsx * sx)] = idx_buffer_view
#         else:
#             idx_buffer = idx_buffer_view

#         # We set dst tokens to be -1 and src to be 0, so an argsort gives us dst|src indices
#         rand_idx = idx_buffer.reshape(1, -1, 1).argsort(dim=1)

#         # We're finished with these
#         del idx_buffer, idx_buffer_view

#         # rand_idx is currently dst|src, so split them
#         num_dst = hsy * wsx
#         a_idx = rand_idx[:, num_dst:, :] # src
#         b_idx = rand_idx[:, :num_dst, :] # dst

#         def split(x):
#             C = x.shape[-1]
#             src = gather(x, dim=1, index=a_idx.expand(B, N - num_dst, C))
#             dst = gather(x, dim=1, index=b_idx.expand(B, num_dst, C))
#             return src, dst

#         # Cosine similarity between A and B
#         metric = metric / metric.norm(dim=-1, keepdim=True)
#         a, b = split(metric)
#         scores = a @ b.transpose(-1, -2)

#         # Can't reduce more than the # tokens in src
#         r = min(a.shape[1], r)

#         # Find the most similar greedily
#         node_max, node_idx = scores.max(dim=-1)
#         edge_idx = node_max.argsort(dim=-1, descending=True)[..., None]

#         unm_idx = edge_idx[..., r:, :]  # Unmerged Tokens
#         src_idx = edge_idx[..., :r, :]  # Merged Tokens
#         dst_idx = gather(node_idx[..., None], dim=-2, index=src_idx)

#     def merge(x: torch.Tensor, mode="mean") -> torch.Tensor:
#         src, dst = split(x)
#         n, t1, c = src.shape
        
#         unm = gather(src, dim=-2, index=unm_idx.expand(n, t1 - r, c))
#         src = gather(src, dim=-2, index=src_idx.expand(n, r, c))
#         dst = dst.scatter_reduce(-2, dst_idx.expand(n, r, c), src, reduce=mode)

#         return torch.cat([unm, dst], dim=1)

#     def unmerge(x: torch.Tensor) -> torch.Tensor:
#         unm_len = unm_idx.shape[1]
#         unm, dst = x[..., :unm_len, :], x[..., unm_len:, :]
#         _, _, c = unm.shape

#         src = gather(dst, dim=-2, index=dst_idx.expand(B, r, c))

#         # Combine back to the original shape
#         out = torch.zeros(B, N, c, device=x.device, dtype=x.dtype)
#         out.scatter_(dim=-2, index=b_idx.expand(B, num_dst, c), src=dst)
#         out.scatter_(dim=-2, index=gather(a_idx.expand(B, a_idx.shape[1], 1), dim=1, index=unm_idx).expand(B, unm_len, c), src=unm)
#         out.scatter_(dim=-2, index=gather(a_idx.expand(B, a_idx.shape[1], 1), dim=1, index=src_idx).expand(B, r, c), src=src)

#         return out

#     return merge, unmerge
