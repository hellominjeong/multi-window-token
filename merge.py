import torch
import torch.nn.functional as F
from typing import Tuple, Callable
import math

def do_nothing(x: torch.Tensor, mode: str = None):
    return x

def mps_gather_workaround(input, dim, index):
    if input.shape[-1] == 1:
        return torch.gather(
            input.unsqueeze(-1),
            dim - 1 if dim < 0 else dim,
            index.unsqueeze(-1)
        ).squeeze(-1)
    else:
        return torch.gather(input, dim, index)

def create_windows(metric: torch.Tensor, w: int, h: int, window_size: int) -> Tuple[torch.Tensor, int, int]:
    """
    Converts token data to windows.

    Args:
        metric (torch.Tensor): Input tensor [B, N, C].
        w (int): Width of the image in tokens.
        h (int): Height of the image in tokens.
        window_size (int): Size of the window.

    Returns:
        Tuple[torch.Tensor, int, int]: Windows tensor, num_windows_h, num_windows_w.
    """
    B, N, C = metric.shape
    assert N == w * h, "The metric size doesn't match width and height."

    # Reshape to [B, H, W, C]
    metric_reshaped = metric.view(B, h, w, C)

    # Create windows: [B, num_windows_h, num_windows_w, window_size, window_size, C]
    num_windows_h = h // window_size
    num_windows_w = w // window_size
    windows = metric_reshaped.unfold(1, window_size, window_size).unfold(2, window_size, window_size)

    # Flatten windows: [B, num_windows, window_size * window_size, C]
    windows = windows.contiguous().view(
        B, num_windows_h * num_windows_w, window_size * window_size, C
    )
    return windows, num_windows_h, num_windows_w

def calculate_similarity(windows: torch.Tensor) -> torch.Tensor:
    """
    Calculate cosine similarity between windows without averaging.

    Args:
        windows (torch.Tensor): Windows tensor [B, num_windows, W*W, C].

    Returns:
        torch.Tensor: Similarity matrix [B, num_windows, num_windows].
    """
    # [B, num_windows, W*W, C] -> [B, num_windows, W*W*C]
    window_features = windows.flatten(start_dim=2)  # ìœˆë„ìš° ë‚´ë¶€ ëª¨ë“  í† í°ì„ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ë³€í™˜

    # ì •ê·œí™”ëœ íŠ¹ì§•ì„ í•œ ë²ˆì— ê³„ì‚°
    norm = torch.norm(window_features, dim=-1, keepdim=True)
    normalized_features = window_features / (norm + 1e-6)

    # ë°°ì¹˜ í–‰ë ¬ ê³± ì‚¬ìš©í•˜ì—¬ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    return torch.bmm(normalized_features, normalized_features.transpose(-2, -1))

def merge_windows(windows: torch.Tensor, similarity_matrix: torch.Tensor, r: int, mode="mean") -> torch.Tensor:
    """
    Merge similar windows using similarity matrix and remove r windows.

    Args:
        windows (torch.Tensor): Windows tensor [B, num_windows, window_size, C].
        similarity_matrix (torch.Tensor): Similarity matrix [B, num_windows, num_windows].
        r (int): Number of merges to perform.
        mode (str): Merge mode ('mean' or 'sum').

    Returns:
        torch.Tensor: Reduced merged windows tensor [B, num_windows - r, window_size, C].
    """
    B, num_windows, window_size, C = windows.shape
    similarity_matrix = similarity_matrix.clone()
    similarity_matrix[:, torch.arange(num_windows), torch.arange(num_windows)] = float('-inf')  # ìê¸° ìì‹  ì œì™¸
    r_windows = int(num_windows * 0.4)  # ì…ë ¥ í…ì„œ ê¸°ë°˜ì´ ì•„ë‹ˆë¼, ìœˆë„ìš° ê°œìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜
    valid_r = min(r_windows, num_windows // 2)  # ë™ì¼í•œ ê¸°ì¤€ìœ¼ë¡œ ë¹„êµ
    # valid_r = min(r, num_windows // 2, similarity_matrix.shape[-1]) 
    print("valid_r: ",valid_r)
    print("r: ",r_windows)
    # âœ… ì„ íƒëœ ìœˆë„ìš°ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
    selected_idx1 = []
    selected_idx2 = []
    num_selected = 0
    print(f"num_selected: {num_selected}, valid_r: {valid_r}")
    while num_selected < valid_r:
        values, indices = similarity_matrix.view(B, -1).topk(valid_r - num_selected, dim=-1)  # ì•„ì§ í•„ìš”í•œ ê°œìˆ˜ë§Œí¼ë§Œ ê°€ì ¸ì˜¤ê¸°
        new_idx1 = indices // num_windows
        new_idx2 = indices % num_windows
        print("new idx1: ",new_idx1.shape)
        print("new idx2: ",new_idx2.shape)
        # âœ… ì¤‘ë³µ ì œê±°
        # mask = ~torch.isin(new_idx1, torch.tensor(selected_idx1, device=similarity_matrix.device)) & \
        #     ~torch.isin(new_idx2, torch.tensor(selected_idx2, device=similarity_matrix.device))
        mask1 = ~torch.isin(new_idx1, torch.tensor(selected_idx1, device=similarity_matrix.device).unsqueeze(0))
        mask2 = ~torch.isin(new_idx2, torch.tensor(selected_idx2, device=similarity_matrix.device).unsqueeze(0))

        # âœ… batch-wise AND ì—°ì‚° ì ìš©
        mask = mask1 & mask2  # ì´ì œ (2, 128) ì°¨ì› ìœ ì§€ë¨
        new_idx1 = new_idx1[mask].view(B, -1)
        new_idx2 = new_idx2[mask].view(B, -1)
        print("after ì¤‘ë³µì œê±° --------------------")
        print("new idx1: ",new_idx1.shape)
        print("new idx2: ",new_idx2.shape)
        # âœ… ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•˜ë©´ì„œ ì •í™•íˆ 128ê°œë¥¼ ìœ ì§€
        selected_idx1.extend(new_idx1.tolist())
        selected_idx2.extend(new_idx2.tolist())
        num_selected = len(selected_idx1[1])  # ì—…ë°ì´íŠ¸
        print("num_selected: ",num_selected)

    # âœ… ìµœì¢… ì„ íƒëœ ì¸ë±ìŠ¤ë¥¼ í…ì„œë¡œ ë³€í™˜
    idx1 = torch.tensor(selected_idx1, device=similarity_matrix.device).view(B, -1)
    idx2 = torch.tensor(selected_idx2, device=similarity_matrix.device).view(B, -1)

    print(f"idx1 unique count: {len(torch.unique(idx1))}")
    print(f"idx2 unique count: {len(torch.unique(idx2))}")
    print(f"idx1.shape before filtering: {idx1.shape}")
    print(f"idx2.shape before filtering: {idx2.shape}") 
    # merged = (windows[:, idx1] + windows[:, idx2]) / 2  # ë‘ ìœˆë„ìš° í‰ê·  ë‚´ê¸°
    unique_pairs = idx1 != idx2  # ê°™ì€ ìœˆë„ìš°ê°€ ì„ íƒë˜ì§€ ì•Šë„ë¡ í•„í„°ë§
    idx1_filtered = [torch.masked_select(idx1[b], unique_pairs[b]) for b in range(B)]
    idx2_filtered = [torch.masked_select(idx2[b], unique_pairs[b]) for b in range(B)]
    idx1_final = torch.cat(idx1_filtered).view(B, -1)
    idx2_final = torch.cat(idx2_filtered).view(B, -1)

    print(f"idx1.shape after filtering: {idx1_final.shape}")
    print(f"idx2.shape after filtering: {idx2_final.shape}")
    unique_idx2, inverse_indices, counts = torch.unique(idx2_final, return_inverse=True, return_counts=True)
    duplicate_idx2 = unique_idx2[counts > 1]  # ì¤‘ë³µëœ idx2 ì°¾ê¸°
    if unique_idx2.shape[0] > valid_r:
        unique_idx2 = unique_idx2[:valid_r]  # valid_r ê°œë§Œ ìœ ì§€
    print(f"Unique idx2 count after fixing: {unique_idx2.shape[0]} (Expected: {valid_r})")

    # âœ… ë³‘í•© ìˆ˜í–‰
    merged = (windows[:, idx1_final] + windows[:, idx2_final]) / 2  
    merged = merged.mean(dim=1)  # âœ… ì°¨ì› ì¡°ì •
    actual_r = idx1_final.shape[1]  # ì‹¤ì œ ë³‘í•©ëœ ê°œìˆ˜ ë°˜ì˜
    print(f"actual_r after filtering: {actual_r}")
    if actual_r == 0:
        print("âš  Warning: No valid merge pairs found. Skipping merge step.")
        return windows

    # âœ… ê¸°ì¡´ ìœˆë„ìš°ì—ì„œ ì œê±°í•  ìœˆë„ìš° ì œì™¸
    mask = torch.ones(num_windows, device=windows.device, dtype=torch.bool)
    idx2_final_unique = torch.unique(idx2_final)  # ì¤‘ë³µ ì œê±°
    print("idx2_final_unique : ", idx2_final_unique)
    mask[idx2_final_unique.flatten()] = False  # ì œê±°í•  ìœˆë„ìš° Falseë¡œ ì„¤ì •
    print(f"mask.sum(): {mask.sum()}")
    print("unique_idx2 : ", unique_idx2)
    # ğŸ”¥ ì¶”ê°€ ìˆ˜ì •: unique_idx2ì™€ duplicate_idx2ë„ Falseë¡œ ì„¤ì •
    mask[unique_idx2] = False  
    print(f"mask.sum(): {mask.sum()}")
    print("duplicate_idx2 : ", duplicate_idx2)
    mask[duplicate_idx2] = False  

    '''
    mask[idx2_final.flatten()] = False  
    # unique_idx2, counts = torch.unique(idx2_final, return_counts=True)
    mask[unique_idx2] = False  # ì¤‘ë³µ ì œê±°ëœ idx2ë§Œ False ì²˜ë¦¬
    mask[duplicate_idx2] = False  # ğŸ›‘ ì¶”ê°€: ì¤‘ë³µëœ idx2ë„ Falseë¡œ ì²˜ë¦¬  
    '''
    
    print(f"mask.sum(): {mask.sum()} (Should be {num_windows - actual_r})")
    remaining_windows = windows[:, mask]
    print(f"remaining_windows.shape: {remaining_windows.shape}")

    print(f"merged.shape before fixing: {merged.shape}")  

    merged_windows = merged
    print(f"Windows after merging shape: {merged_windows.shape}, mean: {merged_windows.mean()}")

    return merged_windows, actual_r

def reconstruct_from_windows(windows: torch.Tensor, num_windows_h: int, num_windows_w: int, 
                             window_size: int, num_windows: int) -> torch.Tensor:
    """
    ìœˆë„ìš° í˜•íƒœë¥¼ ì›ë˜ ì´ë¯¸ì§€ ê³µê°„ìœ¼ë¡œ ë³µì›í•˜ëŠ” í•¨ìˆ˜.

    Args:
        windows (torch.Tensor): ìœˆë„ìš° í…ì„œ [B, num_windows, W*W, C]
        num_windows_h (int): ë†’ì´ ë°©í–¥ ìœˆë„ìš° ê°œìˆ˜
        num_windows_w (int): ë„ˆë¹„ ë°©í–¥ ìœˆë„ìš° ê°œìˆ˜
        window_size (int): ê°œë³„ ìœˆë„ìš° í¬ê¸°
        num_windows (int): ì‹¤ì œ ìœˆë„ìš° ê°œìˆ˜

    Returns:
        torch.Tensor: ë³µì›ëœ ì´ë¯¸ì§€ [B, N, C] í˜•íƒœ
    """
    B, actual_num_windows, _, C = windows.shape

    # âœ… `num_windows_h * num_windows_w`ê°€ `num_windows`ì™€ ë‹¤ë¥¼ ê²½ìš° ì¡°ì •
    if num_windows_h * num_windows_w != num_windows:
        print(f"âš  Warning: Adjusting num_windows_h and num_windows_w. Expected: {num_windows}, Actual: {num_windows_h * num_windows_w}")
        
        # ê°€ì¥ ê°€ê¹Œìš´ num_windows_hì™€ num_windows_w ì°¾ê¸°
        factor_pairs = [(h, num_windows // h) for h in range(1, num_windows + 1) if num_windows % h == 0]
        best_pair = min(factor_pairs, key=lambda p: abs(p[0] - p[1]))  # ê°€ì¥ ë¹„ìœ¨ì´ ë¹„ìŠ·í•œ ì¡°í•© ì„ íƒ
        num_windows_h, num_windows_w = best_pair

        print(f"ğŸ”„ Adjusted num_windows_h: {num_windows_h}, num_windows_w: {num_windows_w}")

    # âœ… `view()`ë¥¼ ì‚¬ìš©í•˜ê¸° ì „ì— í¬ê¸° ë§ì¶”ê¸°
    try:
        windows = windows.view(B, num_windows_h, num_windows_w, window_size, window_size, C)
    except RuntimeError as e:
        print(f"âŒ view() ì‹¤íŒ¨: {e}, windows.shape: {windows.shape}, num_windows_h: {num_windows_h}, num_windows_w: {num_windows_w}")
        return windows  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ë³¸ ìœˆë„ìš° ë°˜í™˜

    # âœ… ìœˆë„ìš°ë¥¼ ë‹¤ì‹œ ì´ë¯¸ì§€ í˜•íƒœë¡œ ë³µì›
    reconstructed = windows.permute(0, 1, 3, 2, 4, 5).contiguous()
    reconstructed = reconstructed.view(B, num_windows_h * window_size, num_windows_w * window_size, C)

    # âœ… `[B, N, C]` í˜•íƒœë¡œ ë³€í™˜
    return reconstructed.view(B, num_windows_h * window_size * num_windows_w * window_size, C)

def window_based_soft_matching(
    input_tensor: torch.Tensor,
    w: int,
    h: int,
    r: int,
    mode="mean"
) -> torch.Tensor:
    """
    Perform window-based soft matching and merging.

    Args:
        input_tensor (torch.Tensor): Input tensor [B, N, C].
        w (int): Width of the image in tokens.
        h (int): Height of the image in tokens.
        r (int): Number of merges to perform.
        mode (str): Merge mode ('mean' or 'sum').

    Returns:
        torch.Tensor: Reconstructed tensor [B, N, C].
    """
    B, N, C = input_tensor.shape
    device = input_tensor.device

    # **ğŸ”¹ Step 1: 4Ã—4 ìœˆë„ìš° ìƒì„± ë° Merge ìˆ˜í–‰**
    windows_4, num_windows_h_4, num_windows_w_4 = create_windows(input_tensor, w, h, window_size=4)
    similarity_matrix_4 = calculate_similarity(windows_4)
    print(f"Before merging: {windows_4.shape}")  # ë³‘í•© ì „
    merged_windows_4, numw4 = merge_windows(windows_4, similarity_matrix_4, r, mode)
    print(f"After merging: {merged_windows_4.shape}")  # ë³‘í•© í›„
    print(f"merged_windows_4.shape: {merged_windows_4.shape}")
    # reconstructed_4 = reconstruct_from_windows(merged_windows_4, num_windows_h_4, num_windows_w_4, 4, h, w)
    reconstructed_4 = reconstruct_from_windows(merged_windows_4, num_windows_h_4, num_windows_w_4, 4, numw4)

    # **ğŸ”¹ Step 2: 16Ã—16 ìœˆë„ìš° ìƒì„± ë° Merge ìˆ˜í–‰**
    windows_16, num_windows_h_16, num_windows_w_16 = create_windows(input_tensor, w, h, window_size=16)
    similarity_matrix_16 = calculate_similarity(windows_16)
    merged_windows_16, numw16 = merge_windows(windows_16, similarity_matrix_16, r, mode)
    # reconstructed_16 = reconstruct_from_windows(merged_windows_16, num_windows_h_16, num_windows_w_16, 16, h, w)
    reconstructed_16 = reconstruct_from_windows(merged_windows_16, num_windows_h_16, num_windows_w_16, 16, numw16)

    # **ğŸ”¹ Step 3: Interpolationì„ í†µí•´ í¬ê¸° ë§ì¶”ê¸° (ì´ì œì•¼ ìˆ˜í–‰)**
    reconstructed_4_resized = F.interpolate(reconstructed_4.permute(0, 2, 1), size=N, mode='linear').permute(0, 2, 1)
    reconstructed_16_resized = F.interpolate(reconstructed_16.permute(0, 2, 1), size=N, mode='linear').permute(0, 2, 1)

    # **ğŸ”¹ Step 4: Concatenation ìˆ˜í–‰**
    result = torch.cat([reconstructed_4_resized, reconstructed_16_resized], dim=-1)

    print(f"result_direct.shape: {result.shape}")  # ì´ ê³¼ì •ì´ ì •ìƒ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸

    return result
